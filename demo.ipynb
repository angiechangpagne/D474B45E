{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "from deepmusic.moduleloader import ModuleLoader\n",
    "#predict next key\n",
    " from deepmusic.keyboardcell import KeyboardCell\n",
    " #encapsulate song data so run get_scale, get_relative_methods\n",
    " import deepmusic.songstrcut as music\n",
    " import numpy as np #generate random numbers\n",
    " import tensorflow as tf # music NN flow\n",
    "\n",
    " def build_network(self):\n",
    "     #create computation graph, encapsulate session and graph init\n",
    "     imput_dim = ModuleLoader.batch_builders.get_module().get_input_dim()\n",
    "\n",
    "#note data\n",
    "with tf.name('placeholder_inputs');\n",
    "    self.inputs = [\n",
    "        tf.placeholder(\n",
    "            tf.float32, #numerical data\n",
    "            [self.args.batch_size, input_dim],\n",
    "            name = 'input' #how much data\n",
    "        )\n",
    "    ]\n",
    "    #targets 88 key binary classification problem, \n",
    "    with tf.name_scope('plaecholder_targets');\n",
    "        self.targets = [\n",
    "            tf.placeholder(\n",
    "                tf.int32,\n",
    "                [self.batch_size],\n",
    "                name='target'\n",
    "            )\n",
    "        ]\n",
    "    #RNN, use previous hidden state for \n",
    "\n",
    "    #hidden state\n",
    "    with tf.name_scope('placeholder_use_prev'):\n",
    "        self.us_prev = [\n",
    "            tf.placeholder(\n",
    "                tf.bool,\n",
    "                [],\n",
    "                name = 'use_prev'\n",
    "            )\n",
    "        ]\n",
    "    #define out network \n",
    "    self.loop_processing = ModuleLoader.loop_processings.build._module(self.args)\n",
    "def loop_rnn(prev,i);\n",
    "    next_input = self.loop_processing(prev)\n",
    "    return ts.cond(self.prev[i], lambda: next_input, lambda: self.inputs[i])\n",
    "\n",
    "#build seq2seq model\n",
    "self.outputs, self.final_state = tf.nn.seq2seq.rnn_decoder(\n",
    "    decoder_inputs = self.inputs, \n",
    "    initial_state=None,\n",
    "    cell=KeyboardCell,\n",
    "    loop_function=loop_rnn\n",
    ") #because defined in keyboard cell\n",
    "\n",
    "#training step define loss function \n",
    "loss_fct = tf.nn.seq2seq_loss(\n",
    "    self.outputs,\n",
    "    self.targets,\n",
    "    softmax_loss_function=tf.nn.softmax.cross_entropy_with_logits,\n",
    "    average_across_timestamps=True,\n",
    "    average_across_batch= True\n",
    ")\n",
    "\n",
    "#initialize the optimizer, minimize the loss\n",
    "opt = tf.train.AdamOptimizer(\n",
    "    learning_rate=self.current_learning_rate,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    epsilon=1e-08\n",
    ")\n",
    "self.opt_op=opt.minimize(loss_fct)\n"
   ]
  }
 ]
}